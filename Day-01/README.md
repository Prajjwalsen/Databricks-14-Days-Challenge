# ğŸ“… Day 01 â€“ Platform Setup & First Steps (Databricks)

## ğŸš€ Databricks 14 Days AI Challenge
This repository documents my learning journey for **Day 01** of the  
**Databricks 14 Days AI Challenge** by **Indian Data Club**.

---

## ğŸ“Œ What I Learned
- Why Databricks is used over Pandas/Hadoop
- Basics of Lakehouse Architecture
- Databricks Workspace structure
- Introduction to PySpark DataFrames
- Loading external datasets using Kaggle API

---

## ğŸ› ï¸ Tasks Completed
âœ… Created Databricks Community Edition account  
âœ… Explored Workspace, Compute, Catalog  
âœ… Created first Databricks notebook  
âœ… Executed basic PySpark operations  
âœ… Downloaded and loaded Kaggle dataset  

---

## ğŸ§ª Hands-on Implementation

### ğŸ”¹ 1. Databricks Workspace & Notebook Setup
![Workspace Setup](Screenshots/Screenshot%202026-01-09%20173625.png)

---

### ğŸ”¹ 2. Creating PySpark DataFrame
![PySpark DataFrame](Screenshots/Screenshot%202026-01-09%20173757.png)

---

### ğŸ”¹ 3. Filtering Data using PySpark
![Filter Step 1](Screenshots/Screenshot%202026-01-09%20173723.png)

![Filter Step 2](Screenshots/Screenshot%202026-01-09%20173732.png)

---

### ğŸ”¹ 4. Kaggle Dataset Loaded into Databricks
![Kaggle Dataset](Screenshots/Screenshot%202026-01-09%20173747.png)

---

## ğŸ§  Key Takeaways
- Databricks simplifies big data processing using Spark
- PySpark operations are fast and scalable
- Lakehouse architecture combines Data Lake + Data Warehouse benefits

---

## ğŸ“‚ Repository Structure
```text
Databricks-14-Days-Challenge/
â”‚
â”œâ”€â”€ Day-01/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ Screenshots/
â”‚       â”œâ”€â”€ 01_workspace_setup.png
â”‚       â”œâ”€â”€ 02_pyspark_dataframe.png
â”‚       â”œâ”€â”€ 03_filter_operation.png
â”‚       â””â”€â”€ 04_kaggle_dataset_loaded.png
â”‚
â””â”€â”€ README.md
